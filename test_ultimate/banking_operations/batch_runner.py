import sys
import importlib
import os
from dotenv import load_dotenv

# Asegurar que podemos importar desde el directorio actual
sys.path.append(os.path.dirname(__file__))

from stress_test_runner import UltimateStressTestRunner, AVAILABLE_BOTS

load_dotenv()

# ==========================================
# CONFIGURACI√ìN DEL BATCH DE PRUEBAS
# ==========================================
# Define aqu√≠ las combinaciones de Bot y Modelo que deseas probar.
# bot_id: Corresponde a las claves en AVAILABLE_BOTS (1-6)
# model: Nombre del modelo (ej: gpt-4o-mini, deepseek-chat)
# provider: Proveedor del modelo (openai, deepseek). Default: openai

TEST_CONFIGS = [
    {"bot_id": "5", "model": "gpt-4o-mini", "provider": "openai"}, # TaskerBot
    {"bot_id": "6", "model": "gpt-4o-mini", "provider": "openai"}, # LangChainBot
]

def resolve_bot_class(bot_id):
    """Resuelve la clase del bot a partir del ID."""
    if bot_id not in AVAILABLE_BOTS:
        print(f"‚ö†Ô∏è  Advertencia: Bot ID '{bot_id}' no encontrado. Saltando.")
        return None, None

    bot_info = AVAILABLE_BOTS[bot_id]
    try:
        module = importlib.import_module(bot_info["module"])
        bot_class = getattr(module, bot_info["class"])
        return bot_class, bot_info["name"]
    except ImportError as e:
        print(f"‚ùå Error importando {bot_info['name']}: {e}")
        return None, None
    except AttributeError:
        print(f"‚ùå Clase {bot_info['class']} no encontrada en {bot_info['module']}")
        return None, None

def run_batch():
    print(f"üöÄ INICIANDO BATCH STRESS TEST ({len(TEST_CONFIGS)} configuraciones)...")
    print("="*60)

    successful_runs = 0
    failed_runs = 0

    for i, config in enumerate(TEST_CONFIGS, 1):
        bot_id = config.get("bot_id")
        model_name = config.get("model", "gpt-4o-mini")
        provider = config.get("provider", "openai")

        bot_class, bot_name = resolve_bot_class(bot_id)

        if not bot_class:
            failed_runs += 1
            continue

        print(f"\n‚ñ∂Ô∏è  EJECUTANDO RUN {i}/{len(TEST_CONFIGS)}")
        print(f"   ü§ñ Bot: {bot_name}")
        print(f"   üß† Modelo: {model_name}")
        print(f"   üåê Proveedor: {provider}")
        print("-" * 30)

        try:
            # Instanciar y ejecutar el runner
            runner = UltimateStressTestRunner(bot_class, bot_name, model_name, provider=provider)
            runner.run_all_tests()
            successful_runs += 1
            print(f"‚úÖ Run {i} completado exitosamente.")

        except Exception as e:
            print(f"‚ùå Run {i} fall√≥ con excepci√≥n: {e}")
            failed_runs += 1

        print("="*60)

    print("\nüèÅ RESUMEN DEL BATCH")
    print(f"   Total Ejecutados: {len(TEST_CONFIGS)}")
    print(f"   Exitosos: {successful_runs}")
    print(f"   Fallidos: {failed_runs}")
    print("="*60)

if __name__ == "__main__":
    # Verificar API Key antes de empezar
    if not os.getenv("OPENAI_API_KEY"):
        print("‚ùå Error: OPENAI_API_KEY no encontrada en variables de entorno.")
        sys.exit(1)

    run_batch()
